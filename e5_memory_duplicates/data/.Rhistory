if (!require(plyr)) {install.packages("plyr"); require(plyr)}
if (!require(lme4)) {install.packages("lme4"); require(lme4)}
if (!require(reshape2)) {install.packages("reshape2"); require(reshape2)}
if (!require(RColorBrewer)) {install.packages("RColorBrewer"); require(RColorBrewer)}
if (!require(Hmisc)) {install.packages("Hmisc"); require(Hmisc)}
if (!require(gridExtra)) {install.packages("gridExtra"); require(gridExtra)}
if (!require(devtools)) {install.packages("devtools"); require(devtools)}
if (!require(ggpubr)) {install.packages("ggpubr"); require(ggpubr)}
if (!require(ggsignif)) {install.packages("ggsignif"); require(ggsignif)}
##================================================================================================================
##IMPORT DATA##
##================================================================================================================
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Set working directory to ../data/
setwd("../data/")
# import data
datalist = list()
files <- list.files(pattern=('*txt'))
for (i in 1:length(files)) {
curData <- fromJSON(files[i], simplifyDataFrame = TRUE)
datalist[[i]] <- curData$trialStruct
}
data = do.call(rbind, datalist)
head(data)
dim(data)
n_bef_excl <- length(unique(data$workerId)); n_bef_excl #201 subjects
#check that we have equal numbers for each condition
table(data$image)
table(data$label)
table(data$agentCond)
table(data$matchCond)
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
# perform exclusions: attention, comprehension, and rts < 100
# note, we exclude based on mean accuracy further below
# note, data$comp_mental_content actually refers to comp_number_copies
data <- subset(data,(data$attentionMCQ=="0" & data$comp_original_you==3 &
data$comp_mental_content==2 & data$comp=='D'))
length(unique(data$workerId))
dim(data)
data$rt[is.na(data$rt)] <- 0
# mark which trials had reasonable rts
for(i in 1:dim(data)[1]) {
if(data$rt[i] >= 100) {
data$badRt[i] = 0
}
else {
data$badRt[i] = 1
}
}
# exclude subjects with lower than 55% average accuracy or rts < 100ms
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
perf_thresh <- 0.55
trial_thresh <- 0.5 #number of trials that need to have rts > 100ms
agentCond <- as.factor(data$agentCond)
ss_excl_mat <- array(0,dim=c(length(workers),2))
colnames(ss_excl_mat) <- c('mean_acc', 'rt_err_prop')
#if their accuracy < 55% or total bad RTs > 50% of trials, exclude them from dataset
for(i in 1:length(workers)) {
ss_excl_mat[i,1] <- c(mean(acc_use[worker==workers[i]])) #accuracy for each worker
ss_excl_mat[i,2] <- sum(data$badRt[data$workerId == workers[i]])/length(data$rt[data$workerId == workers[i]]) #proportion of bad rts
if( (ss_excl_mat[i,1] < perf_thresh) | (ss_excl_mat[i,2] > trial_thresh) ) {
data <- subset(data,data$workerId != workers[i])
}
}
ss_excl_mat
#assign variable names
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
n_aft_excl <- length(workers); n_aft_excl
n_excl <- n_bef_excl - n_aft_excl; n_excl
age <- as.numeric(data$age); mean(age,na.rm = TRUE)
gender <- as.factor(data$sex); table(gender)[1]/sum(table(gender))
##================================================================================================================
##DATA PREP##
##================================================================================================================
identity_bef <- data$identity_fetus #these variables were just mistakenly named
identity_aft <- data$identity_pvs
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
numTrials <- dim(data)[1]
matchCond <- as.factor(data$matchCond)
agentCond <- as.factor(data$agentCond)
for(i in 1:length(agentCond)) {
if(agentCond[i] == 'original') {
data$agentCond_n[i] = 1
}
else if(agentCond[i] == 'copy') {
data$agentCond_n[i] = 2
}
else if(agentCond[i] == 'stranger') {
data$agentCond_n[i] = 3
}
}
agentCond_n <- as.factor(data$agentCond_n)
label <- as.factor(data$label)
ans <- as.factor(data$ans)
corrAns <- as.factor(data$corrAns)
rts <- log(as.numeric(data$rt))
agentConds_n <- as.factor(unique(agentCond_n))
matchConds <- unique(matchCond)
#create matrix for collecting d prime-relevant values, and rts
d_mat <- array(0,dim=c(3*length(workers),7))
colnames(d_mat) <- c('worker', 'agentCond', 'hits', 'false_alarms', 'd', 'rt', 'after_resp')
d.mat <- as.data.frame(d_mat, stringsAsFactors=FALSE); d.mat
#for each worker and agent condition, get average hits, false alarms, d-prime, and rt
#hits: proportion of true hits you said were hits (out of all true hits)
#false alarms: proportin of non hits you said were hits (out of all non hits)
#get rts for trials that were correct
counter <- 1
for(i in 1:length(workers)) {
for(j in 1:length(agentConds_n)) {
length_h <- length(acc_use[worker==workers[i] & agentCond_n==agentConds_n[j] & corrAns=='y'])
length_fa <- length(acc_use[worker==workers[i] & agentCond_n==agentConds_n[j] & corrAns=='n'])
h <- length(acc_use[worker==workers[i] & agentCond_n==agentConds_n[j] & ans=='y' & corrAns=='y'])/length_h
fa <- length(acc_use[worker==workers[i] & agentCond_n==agentConds_n[j] & ans=='y' & corrAns=='n'])/length_fa
rt <- mean(rts[worker==workers[i] & agentCond_n==agentConds_n[j] & acc==1], na.rm=TRUE)
#correction for if h=1 or fa=0, by (Macmillan & Kaplan, 1985)
#if 0, 0.5/𝑛; if 1, (𝑛−0.5)/𝑛 , where n is the number of signal or noise trials
#see https://stats.stackexchange.com/questions/134779/d-prime-with-100-hit-rate-probability-and-0-false-alarm-probability
if(h==1) {
h <- (length_h-0.5)/length_h
}
if(fa==0) {
fa <- 0.05/length_fa
}
d.mat[counter,] <- c (workers[i], agentConds_n[j], h, fa, qnorm(h) - qnorm(fa), rt, mean(identity_aft[worker==workers[i]]))
counter = counter + 1
}
}
#subset d.mat by whether people identified with the original or both
d.mat_o <- subset(d.mat,(d.mat$after==1))
d.mat_b <- subset(d.mat,(d.mat$after==4))
#create matrix for collecting performance difference (self - other) and overall performance
#note, for performance difference we're ignoring people who identified with copy or neither, so perf diff = 0
iden_mat <- array(0,dim=c(length(workers),5))
colnames(iden_mat) <- c('before', 'after','zeros','att_diff', 'total_perf')
for(i in 1:length(workers)) {
iden_mat[i,] <- c( mean(identity_bef[worker==workers[i]]), mean(identity_aft[worker==workers[i]]),0, 0, 0)
}
iden.mat <- as.data.frame(iden_mat, stringsAsFactors=FALSE); iden.mat
for(i in 1:length(workers)) {
if(unique(d.mat$after_resp[d.mat$worker == i]) == 1) { #if they identified with original...
iden.mat[i,4] <- d.mat$d[d.mat$worker==i & d.mat$agentCond == 1] - d.mat$d[d.mat$worker==i & d.mat$agentCond == 3] #original - stranger
}
else if(unique(d.mat$after_resp[d.mat$worker == i]) == 4) { #if they identified with both...
iden.mat[i,4] <- max(d.mat$d[d.mat$worker==i & d.mat$agentCond == 1], (d.mat$d[d.mat$worker==i & d.mat$agentCond == 2])) - d.mat$d[d.mat$worker==i & d.mat$agentCond == 3] #(best of original or copy) - stranger
}
iden.mat[i,5] <- d.mat$d[d.mat$worker==i & d.mat$agentCond == 1] + d.mat$d[d.mat$worker==i & d.mat$agentCond == 2] + d.mat$d[d.mat$worker==i & d.mat$agentCond == 3]
}
#sort identity mat by original - copy
iden_ordered <- iden.mat[order(-iden.mat$att_diff),]
iden_ordered$counter <- c(1:length(workers))
iden_ordered
#make matrix for measuring confusions
conf_mat <- array(0,dim=c(3*length(workers),7))
colnames(conf_mat) <- c('worker', 'after_resp', 'agentCond', 'n_fa', 'n_self', 'n_stranger', 'diff')
conf.mat <- as.data.frame(conf_mat, stringsAsFactors=FALSE); conf.mat
counter <- 1
for(i in 1:length(workers)) {
for(j in 1:length(agentConds_n)) {
total_fa <- length(acc_use[worker==workers[i] & agentCond_n==j & corrAns=='n']) #total mismatching trials
length_fa <- length(acc_use[worker==workers[i] & agentCond_n==j & ans=='y' & corrAns=='n'])/total_fa #proportion of trials that participants false alarmed
length_self <- length(acc_use[worker==workers[i] & agentCond_n==j & ans=='y' & corrAns=='n' & (label == 'original' | label == 'copy')])/total_fa #proportion of those trials that had self labels
length_stranger <- length(acc_use[worker==workers[i] & agentCond_n==j & ans=='y' & corrAns=='n' & label == 'stranger'])/total_fa #proportion of those trials that had stranger labels
conf.mat[counter,] <- c(workers[i], mean(identity_aft[worker==workers[i]]), j, length_fa, length_self, length_stranger, length_self - length_stranger)
counter <- counter + 1
}
}
conf.mat <- subset(conf.mat, conf.mat$after_resp == 4)
##================================================================================================================
##DATA PREP TO REPLICATE REVIVAL EFFECT##
##================================================================================================================
cond1 <- rep(1, times = dim(iden.mat)[1])
cond1_name <- rep('2_dead', times = dim(iden.mat)[1])
cond2 <- rep(2, times = dim(iden.mat)[1])
cond2_name <- rep('1_revived', times = dim(iden.mat)[1])
cond <- c(cond1,cond2)
cond_name <- c(cond1_name, cond2_name)
subject1 <- seq(1, dim(iden.mat)[1], by=1)
subject2 <- seq(1, dim(iden.mat)[1], by=1)
subject <- c(subject1, subject2)
identity_before <- iden.mat$before
identity_after <- iden.mat$after
identity <- c(identity_before, identity_after)
identity_name <- rep(0, times = length(identity))
#code choice names
for(i in 1:length(identity)) {
if(identity[i] == 1) {
identity_name[i] = '1_original'
}
else if(identity[i] == 2) {
identity_name[i] = '2_copy'
}
else if(identity[i] == 3) {
identity_name[i] = '3_neither'
}
else if(identity[i] == 4) {
identity_name[i] = '4_both'
}
}
#code choices for logistic regressions
identity_b_original <- rep(9, times = length(identity))
identity_b_copy <- rep(9, times = length(identity))
identity_b_neither <- rep(9, times = length(identity))
identity_b_both <- rep(9, times = length(identity))
for(i in 1:length(identity)) {
#original = 1, everything else zero
if(identity[i] == 1) {
identity_b_original[i] = 1
identity_b_copy[i] = 0
identity_b_neither[i] = 0
identity_b_both[i] = 0
}
#copy = 1, everything else zero
else if(identity[i] == 2) {
identity_b_original[i] = 0
identity_b_copy[i] = 1
identity_b_neither[i] = 0
identity_b_both[i] = 0
}
#neither = 1, everything else zero
else if(identity[i] == 3) {
identity_b_original[i] = 0
identity_b_copy[i] = 0
identity_b_neither[i] = 1
identity_b_both[i] = 0
}
#both = 1, everything else zero
else if(identity[i] == 4) {
identity_b_original[i] = 0
identity_b_copy[i] = 0
identity_b_neither[i] = 0
identity_b_both[i] = 1
}
}
#export data for multinomial regression in SPSS
export_mat <- array(0,dim=c(length(identity),3))
export_mat <- as.data.frame(export_mat)
colnames(export_mat) <- c('ss', 'cond_name', 'identity_name')
export_mat[,1] <- subject
export_mat[,2] <- cond_name
export_mat[,3] <- identity_name
write.csv(export_mat, 'data_e5.csv')
####============ MULTINOMIAL REGRESSION ============####
# Training the multinomial model
multinom_model <- multinom(identity_name ~ cond_name, data = export_mat)
# Checking the model
summary(multinom_model)
# Calculate p-value from standard error
z <- summary(multinom_model)$coefficients / summary(multinom_model)$standard.errors
p <- (1 - pnorm(abs(z), 0, 1)) * 2
print("p-values: ")
print(p)
source("~/Documents/GitHub/self_duplication_rm_data/e5_memory_duplicates/analysis/e9_memory_duplicates.R")
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment 9
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(jsonlite)) {install.packages("jsonlite"); require(jsonlite)}
if (!require(plyr)) {install.packages("plyr"); require(plyr)}
if (!require(lme4)) {install.packages("lme4"); require(lme4)}
if (!require(reshape2)) {install.packages("reshape2"); require(reshape2)}
if (!require(RColorBrewer)) {install.packages("RColorBrewer"); require(RColorBrewer)}
if (!require(Hmisc)) {install.packages("Hmisc"); require(Hmisc)}
if (!require(gridExtra)) {install.packages("gridExtra"); require(gridExtra)}
if (!require(devtools)) {install.packages("devtools"); require(devtools)}
if (!require(ggpubr)) {install.packages("ggpubr"); require(ggpubr)}
if (!require(ggsignif)) {install.packages("ggsignif"); require(ggsignif)}
##================================================================================================================
##IMPORT DATA##
##================================================================================================================
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Set working directory to ../data/
setwd("../data/")
datalist = list()
#import data using jsonlite [automate this, by defining list of data frames]
files <- list.files(pattern=('*txt'))
for (i in 1:length(files)) {
curData <- fromJSON(files[i], simplifyDataFrame = TRUE)
datalist[[i]] <- curData$trialStruct
}
data = do.call(rbind, datalist)
head(data)
dim(data)
n_bef_excl <- length(unique(data$workerId)); n_bef_excl
#check that we have equal numbers for each condition
table(data$label)
table(data$agentCond)
table(data$selfCond)
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
## (1) attention and comprehension
data <- subset(data,(data$attentionMCQ=="0" & data$comp_original_you == 3
& data$comp_num_copies == 2 & data$comp=="B"))
length(unique(data$workerId)) #1 subjects
data$rt[is.na(data$rt)] <- 0
## (2) < 55 accuracy or RTs < 100ms
#mark which trials had reasonable rts
for(i in 1:dim(data)[1]) {
if(data$rt[i] >= 100) {
data$badRt[i] = 0
}
else {
data$badRt[i] = 1
}
}
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
perf_thresh <- 0.40
cond <- as.factor(data$selfCond)
trial_thresh <- 0.5
ss_excl_mat <- array(0,dim=c(length(workers),2))
colnames(ss_excl_mat) <- c('mean_acc', 'rt_err_prop')
#if their accuracy < 55% or total bad RTs > 50% of trials, exclude them from dataset
for(i in 1:length(workers)) {
ss_excl_mat[i,1] <- c(mean(acc_use[worker==workers[i]])) #get accuracy for each worker
ss_excl_mat[i,2] <- sum(data$badRt[data$workerId == workers[i]])/length(data$rt[data$workerId == workers[i]])
if( (ss_excl_mat[i,1] < perf_thresh) | (ss_excl_mat[i,2] > trial_thresh) ) {
data <- subset(data,data$workerId != workers[i])
}
}
ss_excl_mat
#check it worked
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
ss_excl_mat <- array(0,dim=c(length(workers),2))
colnames(ss_excl_mat) <- c('mean_acc', 'rt_err_prop')
for(i in 1:length(workers)) {
ss_excl_mat[i,1] <- c(mean(acc_use[worker==workers[i]])) #get accuracy for each worker
ss_excl_mat[i,2] <- sum(data$badRt[data$workerId == workers[i]])/length(data$rt[data$workerId == workers[i]])
}
ss_excl_mat
n_aft_excl <- length(unique(data$workerId)); n_aft_excl
n_excl <- n_bef_excl - n_aft_excl; n_excl
age <- as.numeric(data$age); mean(age,na.rm = TRUE)
gender <- as.factor(data$sex); table(gender)[1]/sum(table(gender))
##================================================================================================================
##PREP DATA FOR ANALYSIS##
##================================================================================================================
### get identity ratings for each subject
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
identity_bef <- data$identity_before
identity_aft <- data$identity_after
iden_mat <- array(0,dim=c(length(workers),5))
colnames(iden_mat) <- c('before', 'after','zeros','ltm_diff', 'total_perf')
for(i in 1:length(workers)) {
iden_mat[i,] <- c( mean(identity_bef[worker==workers[i]]), mean(identity_aft[worker==workers[i]]),0, 0, 0)
}
iden.mat <- as.data.frame(iden_mat, stringsAsFactors=FALSE); iden.mat
#assign variable names
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
numTrials <- dim(data)[1]
matchCond <- as.factor(data$matchCond)
agentCond <- as.factor(data$agentCond)
condNum <- as.factor(data$selfCond)
for(i in 1:length(agentCond)) {
if(agentCond[i] == 'original') {
data$agentCond_n[i] = 1
}
else if(agentCond[i] == 'copy') {
data$agentCond_n[i] = 2
}
else if(agentCond[i] == 'stranger') {
data$agentCond_n[i] = 3
}
}
agentCond_n <- as.factor(data$agentCond_n)
ans <- as.factor(data$ans)
corrAns <- as.factor(data$corrAns)
rts <- log(as.numeric(data$rt))
agentConds_n <- as.factor(unique(agentCond_n))
#create matrix for collecting d prime-relevant values, and rts
d_mat <- array(0,dim=c(3*length(workers), 5))
colnames(d_mat) <- c('worker', 'mainCond', 'agentCond', 'acc', 'rt')
d.mat <- as.data.frame(d_mat, stringsAsFactors=FALSE); d.mat
#for each worker and agent condition, get average hits, false alarms, d-prime, and rt
#hits: proportion of true hits you said were hits (out of all true hits)
#false alarms: proportin of non hits you said were hits (out of all non hits)
#get rts for trials that were correct
corr_answers <- c('original', 'copy', 'stranger')
counter <- 1
for(i in 1:length(workers)) {
for(j in 1:length(agentConds_n)) {
mean_acc <- mean(acc_use[worker==workers[i] & agentCond_n==j])
rt <- mean(rts[worker==workers[i] & agentCond_n==j], na.rm=TRUE)
d.mat[counter,] <- c(workers[i], unique(identity_aft[worker==workers[i]]), j, mean_acc, rt)
counter = counter + 1
}
}
# collect total performance and performance difference (cond 1 - 2) for each subject
perf_mat <- array(0, dim=c(length(workers), 3))
colnames(perf_mat) <- c('mainCond', 'perf_diff', 'total_perf')
perf.mat <- as.data.frame(perf_mat, stringsAsFactors=FALSE); perf.mat
for(i in 1:length(workers)) {
perf.mat[i,1] <- unique(d.mat$mainCond[d.mat$worker==i])
if(unique(d.mat$mainCond[d.mat$worker==i]) == 1) {
#performance for original you - performance for stranger John
perf.mat[i,2] <- d.mat$acc[d.mat$worker==i & d.mat$agentCond == 1] - d.mat$acc[d.mat$worker==i & d.mat$agentCond == 2]
}
else if(unique(d.mat$mainCond[d.mat$worker==i]) == 4) {
#best of performance for original or copy - performance for stranger John
perf.mat[i,2] <- max(d.mat$acc[d.mat$worker==i & d.mat$agentCond == 1], d.mat$acc[d.mat$worker==i & d.mat$agentCond == 2]) - d.mat$acc[d.mat$worker==i & d.mat$agentCond == 3]
}
perf.mat[i,3] <- d.mat$acc[d.mat$worker==i & d.mat$agentCond == 1] + d.mat$acc[d.mat$worker==i & d.mat$agentCond == 2] + d.mat$acc[d.mat$worker==i & d.mat$agentCond == 3]
}
##================================================================================================================
##ANALYSIS##
##================================================================================================================
#------- GROUP MEANS--------#
#We only look at conditions in which participants said they were original or both
#Since the other conditions (saying they're the copy or neither) don't have enough subjects
p_mat <- rep(9, times = 3)
star_mat <- rep(9, times = 3)
#one self
d_one <- subset(d.mat, d.mat$mainCond==1)
mean(d_one$acc[d_one$agentCond==1]) #future-you1
sd(d_one$acc[d_one$agentCond==1])
n_o_1 <- length(d_one$acc[d_one$agentCond==1]); n_o_1
mean(d_one$acc[d_one$agentCond==2]) #stranger-john
sd(d_one$acc[d_one$agentCond==2])
n_o_2 <- length(d_one$acc[d_one$agentCond==2]); n_o_2
mean(d_one$acc[d_one$agentCond==3]) #stranger-bill
sd(d_one$acc[d_one$agentCond==3])
n_o_3 <- length(d_one$acc[d_one$agentCond==3])
att_1_o <- t.test(d_one$acc[d_one$agentCond==1 | d_one$agentCond==2] ~ d_one$agentCond[d_one$agentCond==1 | d_one$agentCond==2], var.equal=TRUE, paired=TRUE); att_1_o
att_2_o <- t.test(d_one$acc[d_one$agentCond==1 | d_one$agentCond==3] ~ d_one$agentCond[d_one$agentCond==1 | d_one$agentCond==3], var.equal=TRUE, paired=TRUE); att_2_o
att_3_o <- t.test(d_one$acc[d_one$agentCond==2 | d_one$agentCond==3] ~ d_one$agentCond[d_one$agentCond==2 | d_one$agentCond==3], var.equal=TRUE, paired=TRUE); att_3_o
tes(as.numeric(att_1_o[1]), n_o_1, n_o_2) #cohen's d
tes(as.numeric(att_2_o[1]), n_o_1, n_o_3) #cohen's d
tes(as.numeric(att_3_o[1]), n_o_2, n_o_3) #cohen's d
#two selves
d_two <- subset(d.mat, d.mat$mainCond==4)
mean(d_two$acc[d_two$agentCond==1]) #original
sd(d_two$acc[d_two$agentCond==1])
n_b_1 <- length(d_two$acc[d_two$agentCond==1]); n_b_1
mean(d_two$acc[d_two$agentCond==2]) #copy
sd(d_two$acc[d_two$agentCond==2])
n_b_2 <- length(d_two$acc[d_two$agentCond==2])
mean(d_two$acc[d_two$agentCond==3]) #stranger
sd(d_two$acc[d_two$agentCond==3])
n_b_3 <- length(d_two$acc[d_two$agentCond==3])
att_1_b <- t.test(d_two$acc[d_two$agentCond==1 | d_two$agentCond==2] ~ d_two$agentCond[d_two$agentCond==1 | d_two$agentCond==2], var.equal=TRUE, paired=TRUE); att_1_b
att_2_b <- t.test(d_two$acc[d_two$agentCond==1 | d_two$agentCond==3] ~ d_two$agentCond[d_two$agentCond==1 | d_two$agentCond==3], var.equal=TRUE, paired=TRUE); att_2_b
att_3_b <- t.test(d_two$acc[d_two$agentCond==2 | d_two$agentCond==3] ~ d_two$agentCond[d_two$agentCond==2 | d_two$agentCond==3], var.equal=TRUE, paired=TRUE); att_3_b
tes(as.numeric(att_1_b[1]), n_b_1, n_b_2) #cohen's d
tes(as.numeric(att_2_b[1]), n_b_1, n_b_3) #cohen's d
tes(as.numeric(att_3_b[1]), n_b_2, n_b_3) #cohen's d
#------- TOTAL PERFORMANCE--------#
#summed performance across three agent conditions
mean(perf.mat$total_perf[perf.mat$mainCond == 1])
sd(perf.mat$total_perf[perf.mat$mainCond == 1])
total_n_o <- length(perf.mat$total_perf[perf.mat$mainCond == 1])
mean(perf.mat$total_perf[perf.mat$mainCond == 4])
sd(perf.mat$total_perf[perf.mat$mainCond == 4])
total_n_b <- length(perf.mat$total_perf[perf.mat$mainCond == 4])
perf_1 <- t.test(perf.mat$total_perf[perf.mat$mainCond==1 | perf.mat$mainCond == 4] ~ perf.mat$mainCond[perf.mat$mainCond==1 | perf.mat$mainCond == 4], var.equal=TRUE, paired=FALSE); perf_1
tes(as.numeric(perf_1[1]), total_n_o, total_n_b) #cohen's d
p_mat <- c(att_1_o[3], att_1_b[3], perf_1[3])
for(i in 1:length(p_mat)) {
if(p_mat[i] > 0.10) {
star_mat[i] = 'ns'
}
else if( (p_mat[i] < 0.10) & (p_mat[i] > 0.05) ) {
star_mat[i] = '\u2020'
}
else if( (p_mat[i] < 0.05) & (p_mat[i] > 0.01) ) {
star_mat[i] = '*'
}
else if( (p_mat[i] < 0.01) & (p_mat[i] > 0.001) ) {
star_mat[i] = '**'
}
else if(p_mat[i] < 0.001) {
star_mat[i] = '***'
}
}
#-------PERFORMANCE DIFF --------#
#performance of original - stranger John (self cond 1)
#or best performanc of original or copy - stranger John (self cond 2)
mean(perf.mat$perf_diff[perf.mat$mainCond == 1])
sd(perf.mat$perf_diff[perf.mat$mainCond == 1])
diff_n_o <- length(perf.mat$perf_diff[perf.mat$mainCond == 1])
mean(perf.mat$perf_diff[perf.mat$mainCond == 4])
sd(perf.mat$perf_diff[perf.mat$mainCond == 4])
diff_n_b <- length(perf.mat$perf_diff[perf.mat$mainCond == 4])
perf_2 <- t.test(perf.mat$perf_diff[perf.mat$mainCond==1 | perf.mat$mainCond == 4] ~ perf.mat$mainCond[perf.mat$mainCond==1 | perf.mat$mainCond == 4], var.equal=TRUE, paired=FALSE); perf_2
tes(as.numeric(perf_2[1]), diff_n_o, diff_n_b) #cohen's d
