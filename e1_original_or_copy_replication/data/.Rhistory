#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment 1
## clear workspace
rm(list = ls())
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(lsr)) {install.packages("lsr"); require(lsr)}
if (!require(lsmeans)) {install.packages("lsmean"); require(lsmeans)}
if (!require(nnet)) {install.packages("nnet"); require(nnet)}
if (!require(mlogit)) {install.packages("mlogit"); require(mlogit)}
##================ import data ================================================================================================
# Set wd to current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Set working directory to ../data/
setwd("../data/")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data <- (data <- do.call(rbind, data))
dim(data) #400
##======================== counts and exclusions =============================================================================
#exclude those who failed attention check
data <- subset(data, (data$trialStruct.attention == 0) & (data$trialStruct.comp_number_copies == 2))
#exclude those who failed comprehension check
for(i in 1:dim(data)[1]) {
if( (data$trialStruct.cond_num[i] == 1) & (data$trialStruct.comp_original_you[i] == 1) ) {
data$exclude[i] = 0
}
else if ( (data$trialStruct.cond_num[i] == 2) & (data$trialStruct.comp_original_you[i] == 1) ) {
data$exclude[i] = 0
}
else if ( (data$trialStruct.cond_num[i] == 3) & (data$trialStruct.comp_original_you[i] == 2) ) {
data$exclude[i] = 0
}
else if ( (data$trialStruct.cond_num[i] == 4) & (data$trialStruct.comp_original_you[i] == 2) ) {
data$exclude[i] = 0
}
else {
data$exclude[i] = 1
}
}
data <- subset(data, data$exclude == 0)
dim(data)
age <- as.numeric(data$trialStruct.age); mean(age,na.rm = TRUE) #35.9
gender <- as.factor(data$trialStruct.sex); table(gender)[2]/sum(table(gender)) #48.9
table(gender)
head(data)
data$gender
colnames(data)
data$trialStruct.sex
table(data$trialStruct.sex)
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment 3
## clear workspace
rm(list = ls())
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(lsr)) {install.packages("lsr"); require(lsr)}
if (!require(lsmeans)) {install.packages("lsmean"); require(lsmeans)}
if (!require(nnet)) {install.packages("nnet"); require(nnet)}
if (!require(mlogit)) {install.packages("mlogit"); require(mlogit)}
##================ import baseline condition from e1 ===================================================================================
# Set wd to current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Set working directory to ../e1_original_or_copy/data/
setwd("../../e1_original_or_copy/data/")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data1 <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data1 <- (data1 <- do.call(rbind, data1))
dim(data1) #400
data1 <-subset(data1, data1$trialStruct.cond_num == 3)
data1$trialStruct.cond_num <- 1
data1 <- subset(data1, data1$trialStruct.attention == 0 &
data1$trialStruct.comp_original_you == 2 & data1$trialStruct.comp_number_copies == 2)
dim(data1)
##================ import data from E3 ================================================================================================
# Set wd to current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Set working directory to ../e1_original_or_copy/data/
setwd("../data/")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data2 <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data2 <- (data2 <- do.call(rbind, data2))
dim(data2) #301
data2$trialStruct.cond_num <- data2$trialStruct.cond_num + 1
#exclude those who failed attention and comprehension checks
data2 <- subset(data2, data2$trialStruct.attention == 0 &
data2$trialStruct.comp_original_you == 2 & data2$trialStruct.comp_number_copies == 2)
dim(data2)
age <- as.numeric(data2$trialStruct.age); mean(age,na.rm = TRUE)
gender <- as.factor(data2$trialStruct.sex); table(gender)[2]/sum(table(gender))
table(data$gender)
table(data2$gender)
colnames(data2)
table(data2$trialStruct.sex)
dim(data2)
data2$trialStruct.sex
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment 4
## clear workspace
rm(list = ls())
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(lsr)) {install.packages("lsr"); require(lsr)}
if (!require(lsmeans)) {install.packages("lsmean"); require(lsmeans)}
if (!require(nnet)) {install.packages("nnet"); require(nnet)}
if (!require(mlogit)) {install.packages("mlogit"); require(mlogit)}
if (!require(lme4)) {install.packages("lme4"); require(lme4)}
##================ import data ================================================================================================
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Set working directory to ../data/
setwd("../data/")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data <- (data <- do.call(rbind, data))
n_before_excl <- dim(data); n_before_excl #208
##======================== counts and exclusions ================================================================================
#exclude those who failed attention check
data <- subset(data, data$trialStruct.attention == 0 &
data$trialStruct.comp_original_you == 3 & data$trialStruct.comp_number_copies == 2)
n_after_excl <- dim(data); n_after_excl #176
n_excl <- n_before_excl - n_after_excl; n_excl
age <- as.numeric(data$trialStruct.age); mean(age,na.rm = TRUE) #35.1
gender <- as.factor(data$trialStruct.sex); table(gender)[2]/sum(table(gender)) #56%
table(gender)
76+99+1
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment 5
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(jsonlite)) {install.packages("jsonlite"); require(jsonlite)}
if (!require(plyr)) {install.packages("plyr"); require(plyr)}
if (!require(lme4)) {install.packages("lme4"); require(lme4)}
if (!require(reshape2)) {install.packages("reshape2"); require(reshape2)}
if (!require(RColorBrewer)) {install.packages("RColorBrewer"); require(RColorBrewer)}
if (!require(Hmisc)) {install.packages("Hmisc"); require(Hmisc)}
if (!require(gridExtra)) {install.packages("gridExtra"); require(gridExtra)}
if (!require(devtools)) {install.packages("devtools"); require(devtools)}
if (!require(ggpubr)) {install.packages("ggpubr"); require(ggpubr)}
if (!require(ggsignif)) {install.packages("ggsignif"); require(ggsignif)}
##================================================================================================================
##IMPORT DATA##
##================================================================================================================
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Set working directory to ../data/
setwd("../data/")
# import data
datalist = list()
files <- list.files(pattern=('*txt'))
for (i in 1:length(files)) {
curData <- fromJSON(files[i], simplifyDataFrame = TRUE)
datalist[[i]] <- curData$trialStruct
}
data = do.call(rbind, datalist)
head(data)
dim(data)
n_bef_excl <- length(unique(data$workerId)); n_bef_excl #201 subjects
#check that we have equal numbers for each condition
table(data$image)
table(data$label)
table(data$agentCond)
table(data$matchCond)
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
# perform exclusions: attention, comprehension, and rts < 100
# note, we exclude based on mean accuracy further below
# note, data$comp_mental_content actually refers to comp_number_copies
data <- subset(data,(data$attentionMCQ=="0" & data$comp_original_you==3 &
data$comp_mental_content==2 & data$comp=='D'))
length(unique(data$workerId))
dim(data)
data$rt[is.na(data$rt)] <- 0
# mark which trials had reasonable rts
for(i in 1:dim(data)[1]) {
if(data$rt[i] >= 100) {
data$badRt[i] = 0
}
else {
data$badRt[i] = 1
}
}
# exclude subjects with lower than 55% average accuracy or rts < 100ms
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
perf_thresh <- 0.55
trial_thresh <- 0.5 #number of trials that need to have rts > 100ms
agentCond <- as.factor(data$agentCond)
ss_excl_mat <- array(0,dim=c(length(workers),2))
colnames(ss_excl_mat) <- c('mean_acc', 'rt_err_prop')
#if their accuracy < 55% or total bad RTs > 50% of trials, exclude them from dataset
for(i in 1:length(workers)) {
ss_excl_mat[i,1] <- c(mean(acc_use[worker==workers[i]])) #accuracy for each worker
ss_excl_mat[i,2] <- sum(data$badRt[data$workerId == workers[i]])/length(data$rt[data$workerId == workers[i]]) #proportion of bad rts
if( (ss_excl_mat[i,1] < perf_thresh) | (ss_excl_mat[i,2] > trial_thresh) ) {
data <- subset(data,data$workerId != workers[i])
}
}
ss_excl_mat
#assign variable names
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
n_aft_excl <- length(workers); n_aft_excl
n_excl <- n_bef_excl - n_aft_excl; n_excl
age <- as.numeric(data$age); mean(age,na.rm = TRUE)
gender <- as.factor(data$sex); table(gender)[1]/sum(table(gender))
table(gender)
table(gender)/300
47+73
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment 9
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(jsonlite)) {install.packages("jsonlite"); require(jsonlite)}
if (!require(plyr)) {install.packages("plyr"); require(plyr)}
if (!require(lme4)) {install.packages("lme4"); require(lme4)}
if (!require(reshape2)) {install.packages("reshape2"); require(reshape2)}
if (!require(RColorBrewer)) {install.packages("RColorBrewer"); require(RColorBrewer)}
if (!require(Hmisc)) {install.packages("Hmisc"); require(Hmisc)}
if (!require(gridExtra)) {install.packages("gridExtra"); require(gridExtra)}
if (!require(devtools)) {install.packages("devtools"); require(devtools)}
if (!require(ggpubr)) {install.packages("ggpubr"); require(ggpubr)}
if (!require(ggsignif)) {install.packages("ggsignif"); require(ggsignif)}
##================================================================================================================
##IMPORT DATA##
##================================================================================================================
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Set working directory to ../data/
setwd("../data/")
datalist = list()
#import data using jsonlite [automate this, by defining list of data frames]
files <- list.files(pattern=('*txt'))
for (i in 1:length(files)) {
curData <- fromJSON(files[i], simplifyDataFrame = TRUE)
datalist[[i]] <- curData$trialStruct
}
data = do.call(rbind, datalist)
head(data)
dim(data)
n_bef_excl <- length(unique(data$workerId)); n_bef_excl
#check that we have equal numbers for each condition
table(data$label)
table(data$agentCond)
table(data$selfCond)
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
## (1) attention and comprehension
data <- subset(data,(data$attentionMCQ=="0" & data$comp_original_you == 3
& data$comp_num_copies == 2 & data$comp=="B"))
length(unique(data$workerId)) #1 subjects
data$rt[is.na(data$rt)] <- 0
## (2) < 55 accuracy or RTs < 100ms
#mark which trials had reasonable rts
for(i in 1:dim(data)[1]) {
if(data$rt[i] >= 100) {
data$badRt[i] = 0
}
else {
data$badRt[i] = 1
}
}
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
perf_thresh <- 0.40
cond <- as.factor(data$selfCond)
trial_thresh <- 0.5
ss_excl_mat <- array(0,dim=c(length(workers),2))
colnames(ss_excl_mat) <- c('mean_acc', 'rt_err_prop')
#if their accuracy < 55% or total bad RTs > 50% of trials, exclude them from dataset
for(i in 1:length(workers)) {
ss_excl_mat[i,1] <- c(mean(acc_use[worker==workers[i]])) #get accuracy for each worker
ss_excl_mat[i,2] <- sum(data$badRt[data$workerId == workers[i]])/length(data$rt[data$workerId == workers[i]])
if( (ss_excl_mat[i,1] < perf_thresh) | (ss_excl_mat[i,2] > trial_thresh) ) {
data <- subset(data,data$workerId != workers[i])
}
}
ss_excl_mat
#check it worked
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
ss_excl_mat <- array(0,dim=c(length(workers),2))
colnames(ss_excl_mat) <- c('mean_acc', 'rt_err_prop')
for(i in 1:length(workers)) {
ss_excl_mat[i,1] <- c(mean(acc_use[worker==workers[i]])) #get accuracy for each worker
ss_excl_mat[i,2] <- sum(data$badRt[data$workerId == workers[i]])/length(data$rt[data$workerId == workers[i]])
}
ss_excl_mat
n_aft_excl <- length(unique(data$workerId)); n_aft_excl
n_excl <- n_bef_excl - n_aft_excl; n_excl
age <- as.numeric(data$age); mean(age,na.rm = TRUE)
gender <- as.factor(data$sex); table(gender)[1]/sum(table(gender))
table(gender)
table(gender)/300
table(gender)/30
76+44
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment 2
## clear workspace
rm(list = ls())
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(lsr)) {install.packages("lsr"); require(lsr)}
if (!require(lsmeans)) {install.packages("lsmean"); require(lsmeans)}
if (!require(nnet)) {install.packages("nnet"); require(nnet)}
if (!require(mlogit)) {install.packages("mlogit"); require(mlogit)}
##================ import data ================================================================================================
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Set working directory to ../data/
setwd("../data/")
files <- list.files(pattern=('*txt'))
myJSON <- lapply(files, function(x) fromJSON(file=x)) #join into one single JSON file
(data <- lapply(myJSON, function(myJSON) { as.data.frame(myJSON) }))
data <- (data <- do.call(rbind, data))
dim(data) #400
##======================== counts and exclusions =============================================================================
#exclude those who failed attention check
data <- subset(data, (data$trialStruct.attention == 0) & (data$trialStruct.comp_number_copies == 2))
#exclude those who failed comprehension check
for(i in 1:dim(data)[1]) {
if( (data$trialStruct.cond_num[i] == 1) & (data$trialStruct.comp_original_you[i] == 1) ) {
data$exclude[i] = 0
}
else if ( (data$trialStruct.cond_num[i] == 2) & (data$trialStruct.comp_original_you[i] == 1) ) {
data$exclude[i] = 0
}
else if ( (data$trialStruct.cond_num[i] == 3) & (data$trialStruct.comp_original_you[i] == 2) ) {
data$exclude[i] = 0
}
else if ( (data$trialStruct.cond_num[i] == 4) & (data$trialStruct.comp_original_you[i] == 2) ) {
data$exclude[i] = 0
}
else {
data$exclude[i] = 1
}
}
data <- subset(data, data$exclude == 0)
dim(data)
age <- data$trialStruct.age[data$trialStruct.age %in% 1:100]
mean(age,na.rm = TRUE)
gender <- as.factor(data$trialStruct.sex); table(gender)[2]/sum(table(gender)) #48.9
